{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6140156c-b23b-46e2-ad8c-969fb31ffe4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T03:37:13.563270Z",
     "iopub.status.busy": "2023-10-26T03:37:13.562641Z",
     "iopub.status.idle": "2023-10-26T03:37:13.569120Z",
     "shell.execute_reply": "2023-10-26T03:37:13.567950Z",
     "shell.execute_reply.started": "2023-10-26T03:37:13.563223Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../mypkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b3ca074-33e4-45a2-884a-848e093a09c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T03:37:13.861110Z",
     "iopub.status.busy": "2023-10-26T03:37:13.860453Z",
     "iopub.status.idle": "2023-10-26T03:37:13.870036Z",
     "shell.execute_reply": "2023-10-26T03:37:13.868812Z",
     "shell.execute_reply.started": "2023-10-26T03:37:13.861044Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from numbers import Number\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "from tqdm import trange, tqdm\n",
    "from scipy.io import loadmat\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcde3d6a-1745-4cee-8f69-7fe40dc5a962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T03:37:14.183338Z",
     "iopub.status.busy": "2023-10-26T03:37:14.182774Z",
     "iopub.status.idle": "2023-10-26T03:37:14.194463Z",
     "shell.execute_reply": "2023-10-26T03:37:14.193366Z",
     "shell.execute_reply.started": "2023-10-26T03:37:14.183291Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from constants import DATA_ROOT, RES_ROOT, FIG_ROOT, MIDRES_ROOT\n",
    "from default_paras import def_paras\n",
    "\n",
    "from hdf_utils.data_gen import gen_covs, gen_simu_psd\n",
    "from hdf_utils.fns_sinica import coef_fn, fourier_basis_fn, gen_sini_Xthetas\n",
    "from hdf_utils.likelihood import obt_lin_tm\n",
    "from hdf_utils.SIS import SIS_linear\n",
    "from hdf_utils.utils import gen_lam_seq\n",
    "from hdf_utils.hypo_test import  MS2idxs, obt_test_stat_simple2\n",
    "from utils.matrix import col_vec_fn, col_vec2mat_fn, conju_grad, svd_inverse, cholesky_inv\n",
    "from utils.functions import logit_fn\n",
    "from utils.misc import save_pkl, load_pkl, get_local_min_idxs\n",
    "from splines import obt_bsp_obasis_Rfn, obt_bsp_basis_Rfn_wrapper\n",
    "from projection import euclidean_proj_l1ball\n",
    "from optimization.one_step_opt import OneStepOpt\n",
    "from optimization.cross_validation import CV_err_linear_fn\n",
    "from optimization.variable_selection import GIC_fn, GCV_fn\n",
    "from optimization.opt import optimization\n",
    "from penalties.scad_pen import SCAD\n",
    "from models.linear_model import LinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d03f7c8d-ad04-46e8-aed9-0a11f08ef7d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T03:37:14.563227Z",
     "iopub.status.busy": "2023-10-26T03:37:14.562667Z",
     "iopub.status.idle": "2023-10-26T03:37:14.600001Z",
     "shell.execute_reply": "2023-10-26T03:37:14.598867Z",
     "shell.execute_reply.started": "2023-10-26T03:37:14.563180Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import matplotlib\n",
    "\n",
    "plt.style.use(FIG_ROOT/\"base.mplstyle\")\n",
    "plt.plot([1, 2])\n",
    "plt.close()\n",
    "plt.style.use(FIG_ROOT/\"base.mplstyle\")\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ab0f553-a2cc-4269-8e54-bb7f0a646d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T03:37:14.949098Z",
     "iopub.status.busy": "2023-10-26T03:37:14.948531Z",
     "iopub.status.idle": "2023-10-26T03:37:14.954909Z",
     "shell.execute_reply": "2023-10-26T03:37:14.953836Z",
     "shell.execute_reply.started": "2023-10-26T03:37:14.949051Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import argparse # !!!\n",
    "#parser = argparse.ArgumentParser(description='run')\n",
    "#parser.add_argument('-c', '--cs', type=float, help='cs value') \n",
    "#args = parser.parse_args()\n",
    "\n",
    "args = edict()\n",
    "args.cs = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac6e50-c8cd-4fa1-8421-b9785307e2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d9907b5-461a-42aa-b931-0e0836c6795b",
   "metadata": {},
   "source": [
    "# Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0359200-53b5-4a91-8e56-a0fa4c70eda0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T22:44:55.986311Z",
     "iopub.status.busy": "2023-10-17T22:44:55.985666Z",
     "iopub.status.idle": "2023-10-17T22:44:56.026967Z",
     "shell.execute_reply": "2023-10-17T22:44:56.026426Z",
     "shell.execute_reply.started": "2023-10-17T22:44:55.986269Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         14.87358566]\n"
     ]
    }
   ],
   "source": [
    "cs = [args.cs, 0.0, 0.0] # for sinica paper\n",
    "obt_bsp = obt_bsp_obasis_Rfn\n",
    "np.random.seed(0)\n",
    "paras = edict(def_paras.copy())\n",
    "\n",
    "\n",
    "\n",
    "# Others\n",
    "paras.num_rep = 200 \n",
    "paras.num_rep_cv = 50 \n",
    "paras.init_noise_sd = -1 # the sd of the noise added to the true value for initial values, if -1, make init 0\n",
    "#paras.SIS_ratio = 1 # the ratio to keep with SIS procedure\n",
    "paras.SIS_ratio = 0.2 # the ratio to keep with SIS procedure\n",
    "paras.linear_theta_update=\"cholesky_inv\"\n",
    "paras.is_center = True\n",
    "\n",
    "# candidate sets of tuning parameters, only two \n",
    "# lambda: penalty term\n",
    "# N: num of basis\n",
    "paras.can_lams = [0.001, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50, 2] \n",
    "paras.can_Ns = [4, 6, 8, 10, 12] \n",
    "\n",
    "\n",
    "# generating dataset\n",
    "paras.n = 100 # num of data obs to be genareted\n",
    "paras.npts = 100 # num of pts to evaluate X(s)\n",
    "paras.freqs = np.linspace(2, 45, paras.npts) # freqs\n",
    "paras.d = 200 # num of ROIs\n",
    "paras.q = 1 # num of other covariates\n",
    "paras.sigma2 = 1 # variance of the error\n",
    "paras.types_ = [\"int\"]\n",
    "paras.is_std = False # whether to std PSD across freq or not\n",
    "\n",
    "# b-spline\n",
    "paras.x = np.linspace(0, 1, paras.npts)\n",
    "paras.basis_mats = []\n",
    "for N in paras.can_Ns:\n",
    "    paras.basis_mats.append(\n",
    "        torch.tensor(obt_bsp(paras.x, N, paras.ord)).to(torch.get_default_dtype())\n",
    "    )\n",
    "\n",
    "# True parameters\n",
    "paras.alp_GT = np.array([0])\n",
    "# fourier basis\n",
    "paras.fourier_basis = fourier_basis_fn(paras.x)[:, :]\n",
    "paras.fourier_basis_coefs = ([cs[0]*coef_fn(0.2), cs[1]*coef_fn(0.2), cs[2]*coef_fn(0.2)] + \n",
    "                             [np.zeros(50)] * (paras.d-3-1) +\n",
    "                             [coef_fn(0.2)]\n",
    "                             )\n",
    "paras.fourier_basis_coefs = np.array(paras.fourier_basis_coefs).T \n",
    "paras.beta_GT = paras.fourier_basis @ paras.fourier_basis_coefs\n",
    "beta_GT_norm = np.linalg.norm(paras.beta_GT, axis=0)\n",
    "print(beta_GT_norm)\n",
    "\n",
    "paras.Gam_GT_ests = [(np.linalg.inv(basis_mat.numpy().T \n",
    "                                  @ basis_mat.numpy()) \n",
    "                                  @ basis_mat.numpy().T \n",
    "                                  @ paras.beta_GT) \n",
    "                     for basis_mat in paras.basis_mats]\n",
    "\n",
    "# optimization\n",
    "# not used, to use it, you have to know GT\n",
    "#Rmins = [(2*(np.linalg.norm(paras.Gam_GT_ests[ix]\n",
    "#                            /np.sqrt(paras.can_Ns[ix]), axis=0).sum() \n",
    "#           + np.abs(paras.alp_GT).sum())) \n",
    "#        for ix in range(len(paras.can_Ns))]\n",
    "#paras.Rmin = np.max(Rmins)\n",
    "paras.Rmin = 100000\n",
    "paras.Rfct = 2\n",
    "paras.stop_cv = 5e-4\n",
    "paras.max_iter = 10000\n",
    "paras.num_cv_fold = 5\n",
    "# it is the parametes for SCAD\n",
    "paras.a = 2.7 # before (on Oct 10, 2023), it is 3.7 by default. \n",
    "\n",
    "\n",
    "# hypothesis test\n",
    "#without loss of generality, we assume the idxs in M is the first m betas\n",
    "paras.sel_idx = np.arange(1, paras.d) # M^c set, \n",
    "paras.M_idxs = np.delete(np.arange(paras.d), paras.sel_idx) # the M set\n",
    "paras.Cmats = [\n",
    "    np.eye(len(paras.M_idxs)), # m x m I matrix, [beta1, beta2] = [0, 0]\n",
    "]\n",
    "paras.svdinv_eps_Q = 0 # now 0 means inverse, small value like 0.01 means remove small eig vals.\n",
    "paras.svdinv_eps_Psi = 0\n",
    "\n",
    "\n",
    "# saving path\n",
    "paras.save_dir = RES_ROOT/f\"simu_settingtmp_{cs[0]*1000:.0f}\"\n",
    "if not paras.save_dir.exists():\n",
    "    paras.save_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a461d36-25f3-4376-b945-b6a468dd136d",
   "metadata": {},
   "source": [
    "# Fn to generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "506edd2f-b050-4388-baef-550e626e3524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T22:44:57.468342Z",
     "iopub.status.busy": "2023-10-17T22:44:57.467684Z",
     "iopub.status.idle": "2023-10-17T22:44:57.492933Z",
     "shell.execute_reply": "2023-10-17T22:44:57.492191Z",
     "shell.execute_reply.started": "2023-10-17T22:44:57.468298Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _is_exists(tmp_paras):\n",
    "    \"\"\"\n",
    "    Check if a file with the given parameters exists.\n",
    "\n",
    "    Args:\n",
    "    tmp_paras:\n",
    "        d (int): The value of d in the file name.\n",
    "        n (int): The value of n in the file name.\n",
    "        npts:\n",
    "        is_std\n",
    "        seed (int): The seed value in the file name.\n",
    "\n",
    "    Returns:\n",
    "    bool or Path: Returns the file path if the file exists, otherwise returns False.\n",
    "    \"\"\"\n",
    "    _get_n = lambda fil: int(fil.stem.split(\"_\")[2].split(\"-\")[-1])\n",
    "    fils = MIDRES_ROOT.glob(f\"PSD_d-{tmp_paras.d}_n-*npts-{tmp_paras.npts}_is_std-{tmp_paras.is_std}\")\n",
    "    # We do not need fil with n as we know the data with corresponding seed does not exist\n",
    "    fils = [fil for fil in fils if _get_n(fil) !=tmp_paras.n]\n",
    "    if len(fils) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        fils = sorted(fils, key=_get_n)\n",
    "        ns = np.array([_get_n(fil) for fil in fils])\n",
    "        idxs = np.where(tmp_paras.n <= ns)[0]\n",
    "        if len(idxs) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            fil =fils[idxs[0]]\n",
    "            path = MIDRES_ROOT/fil/f\"seed_{tmp_paras.seed}.pkl\"\n",
    "            return path if path.exists() else False\n",
    "def _get_filename(params):\n",
    "    keys = [\"d\", \"n\", \"npts\", \"is_std\"]\n",
    "    folder_name = 'PSD_'+'_'.join(f\"{k}-{params[k]}\" for k in keys)\n",
    "    return folder_name + f'/seed_{params.seed}.pkl'\n",
    "def _gen_simu_data_all(seed, paras, verbose=False, is_gen=False):\n",
    "    \"\"\"\n",
    "    Generate simulated data for all parameters.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed for random number generator.\n",
    "        paras (dict): Dictionary containing the following parameters:\n",
    "            - n (int): Number of samples.\n",
    "            - d (int): Number of dimensions.\n",
    "            - q (int): Number of covariates.\n",
    "            - types_ (list): List of types for generating covariates.\n",
    "            - alp_GT (list): List of ground truth alpha values.\n",
    "            - beta_GT (list): List of ground truth beta values.\n",
    "            - freqs (list): List of frequencies for generating simulated PSD.\n",
    "            - sigma2 (float): Variance of the noise.\n",
    "        verbose(bool): Verbose or not\n",
    "        is_gen(bool): Only for generating or not. If True, only checking or generating X, not return anything.\n",
    "\n",
    "    Returns:\n",
    "        all_data (dict): Dictionary containing the following simulated data:\n",
    "            - X (torch.Tensor): Tensor of shape (n, d, npts) containing the simulated PSD.\n",
    "            - Y (torch.Tensor): Tensor of shape (n,) containing the response variable.\n",
    "            - Z (torch.Tensor): Tensor of shape (n, q) containing the covariates.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    _paras = edict(paras.copy())\n",
    "    # simulated PSD\n",
    "    assert len(_paras.types_) == _paras.q\n",
    "    assert len(_paras.alp_GT) == _paras.q\n",
    "    tmp_paras = edict()\n",
    "    tmp_paras.seed = seed \n",
    "    tmp_paras.n = _paras.n\n",
    "    tmp_paras.d = _paras.d\n",
    "    tmp_paras.npts = _paras.npts\n",
    "    tmp_paras.is_std = _paras.is_std\n",
    "    \n",
    "    file_path = MIDRES_ROOT/_get_filename(tmp_paras)\n",
    "    if file_path.exists():\n",
    "        if is_gen:\n",
    "            return None\n",
    "        simu_curvs = load_pkl(file_path, verbose=verbose)\n",
    "    else:\n",
    "        ofil =  _is_exists(tmp_paras)\n",
    "        if ofil:\n",
    "            if is_gen:\n",
    "                return None\n",
    "            simu_curvs = load_pkl(ofil, verbose=verbose)\n",
    "        else:\n",
    "            if _paras.is_std:\n",
    "                simu_curvs = gen_simu_psd(_paras.n, _paras.d, _paras.freqs, prior_sd=10, n_jobs=28, is_prog=False, is_std=_paras.is_std)\n",
    "            else:\n",
    "                simu_curvs = gen_simu_psd(_paras.n, _paras.d, _paras.freqs, prior_sd=10, n_jobs=28, is_prog=False, is_std=_paras.is_std)\n",
    "                simu_curvs = simu_curvs - simu_curvs.mean(axis=-1, keepdims=True); # not std, but center it\n",
    "            save_pkl(file_path, simu_curvs, verbose=verbose)\n",
    "    if is_gen:\n",
    "        return None\n",
    "    simu_curvs = simu_curvs[:_paras.n]\n",
    "    simu_curvs = (simu_curvs + np.random.randn(*simu_curvs.shape)*3)*1 # larger\n",
    "    #simu_curvs = np.random.randn(_paras.n, _paras.d, _paras.npts)* 10\n",
    "    simu_covs = gen_covs(_paras.n, _paras.types_)\n",
    "    \n",
    "    # linear term and Y\n",
    "    int_part = np.sum(_paras.beta_GT.T* simu_curvs[:, :, :], axis=1).mean(axis=1)\n",
    "    cov_part = simu_covs @ _paras.alp_GT \n",
    "    \n",
    "    # linear term\n",
    "    lin_term = cov_part + int_part\n",
    "    \n",
    "    # Y \n",
    "    Y = lin_term + np.random.randn(_paras.n)*np.sqrt(_paras.sigma2)\n",
    "    \n",
    "    # center\n",
    "    X_centered = simu_curvs - simu_curvs.mean(axis=0, keepdims=True)\n",
    "    Y_centered = Y - Y.mean(axis=0, keepdims=True)\n",
    "    \n",
    "    # To torch\n",
    "    X = torch.Tensor(X_centered) # n x d x npts\n",
    "    Z = torch.Tensor(simu_covs) # n x q\n",
    "    Y = torch.Tensor(Y_centered)\n",
    "    \n",
    "    all_data = edict()\n",
    "    all_data.X = X\n",
    "    all_data.Y = Y\n",
    "    all_data.Z = Z\n",
    "    all_data.lin_term = lin_term\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7c9b4-7685-462d-b38d-3b2249754691",
   "metadata": {},
   "source": [
    "# Simu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7841633a-7d5e-43a3-97f8-82d46b727943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T23:02:48.679369Z",
     "iopub.status.busy": "2023-10-17T23:02:48.678705Z",
     "iopub.status.idle": "2023-10-17T23:02:48.711401Z",
     "shell.execute_reply": "2023-10-17T23:02:48.710890Z",
     "shell.execute_reply.started": "2023-10-17T23:02:48.679326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _run_fn(seed, lam, N, paras, is_save=False, is_cv=False, verbose=False):\n",
    "    \"\"\"Now (on Aug 25, 2023), if we keep seed the same, the cur_data is the same. \n",
    "       If you want to make any changes, make sure this. \n",
    "    \"\"\"\n",
    "    torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "        \n",
    "    _paras = edict(paras.copy())\n",
    "    _paras.Rv = _paras.Rfct * _paras.Rmin\n",
    "    _paras.seed = seed\n",
    "    _paras.lam = lam\n",
    "    _paras.N = N\n",
    "    _paras.basis_mat = _paras.basis_mats[_paras.can_Ns.index(N)]\n",
    "    _paras.Gam_GT_est = paras.Gam_GT_ests[_paras.can_Ns.index(N)]\n",
    "    cur_data = _gen_simu_data_all(_paras.seed, _paras)\n",
    "    \n",
    "    f_name = f\"seed_{seed:.0f}-lam_{lam*1000:.0f}-N_{N:.0f}-c1_{cs[0]*1000:.0f}_est.pkl\"\n",
    "    \n",
    "    \n",
    "    res = edict()\n",
    "    if not (_paras.save_dir/f_name).exists():\n",
    "        # do sure independent screening for dim reduction\n",
    "        if _paras.SIS_ratio < 1:\n",
    "            keep_idxs, _  = SIS_linear(cur_data.Y, cur_data.X, cur_data.Z, _paras.basis_mats[_paras.can_Ns.index(6)],\n",
    "                                       _paras.SIS_ratio, _paras, ridge_pen=0)\n",
    "        else:\n",
    "            keep_idxs = _paras.sel_idx\n",
    "        M_idxs = np.delete(np.arange(_paras.d), _paras.sel_idx)\n",
    "        _paras.keep_idxs = np.sort(np.concatenate([M_idxs, keep_idxs]))\n",
    "            \n",
    "        _paras.sel_idx_SIS = np.where(np.array([keep_idx in _paras.sel_idx for keep_idx in _paras.keep_idxs]))[0]\n",
    "        _paras.d_SIS = len(_paras.keep_idxs)\n",
    "        \n",
    "        cur_data_SIS = edict(cur_data.copy())\n",
    "        cur_data_SIS.X = cur_data.X[:, _paras.keep_idxs, :]\n",
    "        \n",
    "        \n",
    "        if _paras.init_noise_sd < 0:\n",
    "            alp_init = torch.zeros(_paras.q)\n",
    "            Gam_init = torch.zeros(_paras.N, _paras.d_SIS)\n",
    "            theta_init = torch.cat([alp_init, col_vec_fn(Gam_init)/np.sqrt(_paras.N)])\n",
    "            rhok_init = torch.zeros(_paras.d_SIS*_paras.N)\n",
    "        else:\n",
    "            alp_init = torch.Tensor(_paras.alp_GT) + torch.randn(_paras.q)*_paras.init_noise_sd\n",
    "            Gam_init = torch.Tensor(_paras.Gam_GT_est[:, _paras.keep_idxs]) + torch.randn(_paras.N, _paras.d_SIS)*_paras.init_noise_sd\n",
    "            theta_init = torch.cat([alp_init, col_vec_fn(Gam_init)/np.sqrt(_paras.N)])\n",
    "            rhok_init = torch.randn(_paras.d_SIS*_paras.N)\n",
    "            \n",
    "        model = LinearModel(Y=cur_data_SIS.Y, \n",
    "                            X=cur_data_SIS.X, \n",
    "                            Z=cur_data_SIS.Z, \n",
    "                            basis_mat=_paras.basis_mat, \n",
    "                            sigma2=1)\n",
    "                            #sigma2=_paras.sigma2)\n",
    "        # 3e0\n",
    "        pen = SCAD(lams=_paras.lam, a=_paras.a,  sel_idx=_paras.sel_idx_SIS)\n",
    "            \n",
    "        \n",
    "        main_res = optimization(model=model, \n",
    "                                penalty=pen, \n",
    "                                inits=[alp_init, Gam_init, theta_init, rhok_init],\n",
    "                                is_prg=verbose,\n",
    "                                save_paras=False,    \n",
    "                                input_paras=_paras)\n",
    "        opt = main_res[0]\n",
    "        est_Gam = opt.Gamk\n",
    "        est_alp = opt.alpk\n",
    "        Q_mat = -model.log_lik_der2(est_alp, est_Gam)\n",
    "        model.log_lik_der1(est_alp, est_Gam);\n",
    "        Sig_mat = (model.log_lik_der1_vs.unsqueeze(-1) * model.log_lik_der1_vs.unsqueeze(1)).mean(axis=0) \n",
    "        est_theta = torch.cat([est_alp, col_vec_fn(est_Gam)/np.sqrt(_paras.N)])\n",
    "        nonzero_idxs = torch.nonzero(torch.norm(est_Gam, dim=0)).reshape(-1).numpy()\n",
    "        MS_unions = np.sort(np.union1d(_paras.M_idxs, nonzero_idxs))\n",
    "        keep_idxs_test = MS2idxs(_paras.q, _paras.N, MS_unions)\n",
    "        Q_mat_part = Q_mat[keep_idxs_test][:, keep_idxs_test]\n",
    "        Sig_mat_part = Sig_mat[keep_idxs_test][:, keep_idxs_test]\n",
    "        \n",
    "        res = edict()\n",
    "        _paras.Gam_GT_ests = None\n",
    "        _paras.basis_mats = None\n",
    "        _paras.fourier_basis_coefs = None\n",
    "        _paras.fourier_basis = None\n",
    "        res._paras = _paras\n",
    "        res.Sig_mat_part = Sig_mat_part\n",
    "        res.Q_mat_part = Q_mat_part\n",
    "        res.est_Gam = est_Gam\n",
    "        res.est_alp = est_alp\n",
    "        res.conv_num = main_res[1]\n",
    "        res.est_sigma2 = torch.mean((model.Y - model._obt_lin_tm(est_alp, est_Gam))**2)\n",
    "        res.AIC = GIC_fn(res, \"AIC\")\n",
    "        res.BIC = GIC_fn(res, \"BIC\")\n",
    "        res.GCV = GCV_fn(res)\n",
    "    \n",
    "        if is_cv:\n",
    "            if _paras.init_noise_sd < 0:\n",
    "                alp_init1 = torch.zeros(_paras.q)\n",
    "                Gam_init1 = torch.zeros(_paras.N, _paras.d_SIS)\n",
    "                theta_init1 = torch.cat([alp_init, col_vec_fn(Gam_init)/np.sqrt(_paras.N)])\n",
    "                rhok_init1 = torch.zeros(_paras.d_SIS*_paras.N)\n",
    "            else:\n",
    "                # use a diff initial to reduce the overfitting\n",
    "                alp_init1 = torch.Tensor(_paras.alp_GT) + torch.randn(_paras.q)*_paras.init_noise_sd\n",
    "                Gam_init1 = torch.Tensor(_paras.Gam_GT_est[:, _paras.keep_idxs]) + torch.randn(_paras.N, _paras.d_SIS)*_paras.init_noise_sd\n",
    "                theta_init1 = torch.cat([alp_init, col_vec_fn(Gam_init)/np.sqrt(_paras.N)])\n",
    "                rhok_init1 = torch.randn(_paras.d_SIS*_paras.N)\n",
    "            cv_errs = CV_err_linear_fn(data=cur_data_SIS, \n",
    "                                       penalty=pen, \n",
    "                                       num_cv_fold=_paras.num_cv_fold,\n",
    "                                       # do not use estimated value for initial, severe overfitting !!! (on Aug 25, 2023)\n",
    "                                       inits=[alp_init1, Gam_init1, theta_init1, rhok_init1], \n",
    "                                       is_prg=verbose, \n",
    "                                       save_paras=False,    \n",
    "                                       input_paras=_paras)\n",
    "            \n",
    "            res.cv_errs = cv_errs\n",
    "        else:\n",
    "            res.cv_errs = None\n",
    "        if is_save:\n",
    "            save_pkl(_paras.save_dir/f_name, res, verbose=verbose)\n",
    "    return res\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7f66c-400a-4ec8-9ecc-26f27d953b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "140d9069-aa0b-4974-83a9-5d27e4603ef2",
   "metadata": {},
   "source": [
    "## Find optimal lam and N with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d8c4bc-6ca4-4d55-81cd-964839eafbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9d203c1-b1c2-4dfa-b63f-71c737748619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T23:02:50.098338Z",
     "iopub.status.busy": "2023-10-17T23:02:50.097676Z",
     "iopub.status.idle": "2023-10-17T23:02:50.109127Z",
     "shell.execute_reply": "2023-10-17T23:02:50.108221Z",
     "shell.execute_reply.started": "2023-10-17T23:02:50.098294Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_min_idx(x):\n",
    "    \"\"\"Get the index of the minimal values among the local minimals.\n",
    "       If there are multiple ones, return the largest index\n",
    "       args:\n",
    "           x: a vec\n",
    "        \n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    lmin_idxs = get_local_min_idxs(x);\n",
    "    if len(lmin_idxs) == 0:\n",
    "        lmin_idxs = np.arange(len(x))\n",
    "    lmin_idxs_inv =  lmin_idxs[::-1]\n",
    "    lmins_inv = x[lmin_idxs_inv];\n",
    "    return  lmin_idxs_inv[np.argmin(lmins_inv)]\n",
    "_err_fn = lambda x: np.nanmean(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf7dfdb3-3935-4450-917d-80d9f5c58be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T23:02:50.632019Z",
     "iopub.status.busy": "2023-10-17T23:02:50.631349Z",
     "iopub.status.idle": "2023-10-17T23:03:00.325242Z",
     "shell.execute_reply": "2023-10-17T23:03:00.324090Z",
     "shell.execute_reply.started": "2023-10-17T23:02:50.631976Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                  | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████▍                                                                                 | 40/100 [00:00<00:00, 141.52it/s]\u001b[A\n",
      " 60%|██████████████████████████████████████████████████████████████████████████████████▏                                                      | 60/100 [00:00<00:00, 76.59it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                           | 80/100 [00:01<00:00, 60.36it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 61.68it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "all_coms = itertools.product(range(0, paras.num_rep_cv), paras.can_lams, paras.can_Ns)\n",
    "with Parallel(n_jobs=20) as parallel:\n",
    "    ress = parallel(delayed(_run_fn)(seed, lam=lam, N=N, paras=paras, is_save=True, is_cv=True, verbose=False) \n",
    "                    for seed, lam, N \n",
    "                    in tqdm(all_coms, total=len(paras.can_Ns)*len(paras.can_lams)*paras.num_rep_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "77cc5204-a92e-4992-ae32-e25002f23827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T23:14:07.336472Z",
     "iopub.status.busy": "2023-10-17T23:14:07.335853Z",
     "iopub.status.idle": "2023-10-17T23:14:07.358973Z",
     "shell.execute_reply": "2023-10-17T23:14:07.358239Z",
     "shell.execute_reply.started": "2023-10-17T23:14:07.336430Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal N and lambda are 6.0 and 0.3, respectively\n"
     ]
    }
   ],
   "source": [
    "# get the best lam and N based on CV\n",
    "all_cv_errs = [np.zeros((len(paras.can_Ns), len(paras.can_lams))) for ix in range(paras.num_rep_cv)];\n",
    "res = ress[0]\n",
    "for res in ress:\n",
    "    rowix, colix = paras.can_Ns.index(res._paras.N), paras.can_lams.index(res._paras.lam)\n",
    "    all_cv_errs[res._paras.seed][rowix, colix] = _err_fn(res.cv_errs)\n",
    "    \n",
    "opt_lamNs = []\n",
    "all_cv_err = all_cv_errs[2]\n",
    "for all_cv_err in all_cv_errs:\n",
    "    errs = []\n",
    "    for cur_N, cv_err in zip(paras.can_Ns, all_cv_err):\n",
    "        lam_min_idx = _get_min_idx(cv_err);\n",
    "        errs.append([cur_N, paras.can_lams[lam_min_idx], cv_err[lam_min_idx]])\n",
    "    errs_sorted = sorted(errs, key=lambda x: x[-1])\n",
    "    opt_lamNs.append(errs_sorted[0][:2])\n",
    "opt_lamNs = np.array(opt_lamNs)\n",
    "vs, cts = np.unique(opt_lamNs, axis=0, return_counts=1)\n",
    "optN, optlam = vs[np.argmax(cts)]\n",
    "print(f\"The optimal N and lambda are {optN} and {optlam}, respectively.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3c8f1-bbe7-4bb3-bb64-6dfb5b318289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88621656-e47e-42ae-bfc6-b6ca23e8ed22",
   "metadata": {},
   "source": [
    "## Run the remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7afaf5b7-19f7-4c11-a46e-b5a24da32811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-17T23:02:50.632019Z",
     "iopub.status.busy": "2023-10-17T23:02:50.631349Z",
     "iopub.status.idle": "2023-10-17T23:03:00.325242Z",
     "shell.execute_reply": "2023-10-17T23:03:00.324090Z",
     "shell.execute_reply.started": "2023-10-17T23:02:50.631976Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                  | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████▍                                                                                 | 40/100 [00:00<00:00, 141.52it/s]\u001b[A\n",
      " 60%|██████████████████████████████████████████████████████████████████████████████████▏                                                      | 60/100 [00:00<00:00, 76.59it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                           | 80/100 [00:01<00:00, 60.36it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 61.68it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "with Parallel(n_jobs=20) as parallel:\n",
    "    ress = parallel(delayed(_run_fn)(seed, lam=optlam, N=optN, paras=paras, is_save=True, is_cv=False, verbose=False) \n",
    "                    for seed\n",
    "                    in tqdm(range(paras.num_rep_cv, paras.num_rep), total=(paras.num_rep-paras.num_rep_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580d694-9aa9-49e0-9d8b-c1c8a35810df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
