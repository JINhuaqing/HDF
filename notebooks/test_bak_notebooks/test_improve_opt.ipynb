{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf0a805",
   "metadata": {},
   "source": [
    "This file is to test my code\n",
    "\n",
    "I try to improve my code for HDF to make it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ae980e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T19:57:23.490285Z",
     "start_time": "2023-05-31T19:57:23.481769Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-29T01:37:38.182880Z",
     "iopub.status.busy": "2023-12-29T01:37:38.182409Z",
     "iopub.status.idle": "2023-12-29T01:37:38.196675Z",
     "shell.execute_reply": "2023-12-29T01:37:38.195623Z",
     "shell.execute_reply.started": "2023-12-29T01:37:38.182837Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../mypkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023df78a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T19:57:34.238839Z",
     "start_time": "2023-05-31T19:57:23.494053Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-29T01:37:38.198571Z",
     "iopub.status.busy": "2023-12-29T01:37:38.198068Z",
     "iopub.status.idle": "2023-12-29T01:37:40.754672Z",
     "shell.execute_reply": "2023-12-29T01:37:40.754168Z",
     "shell.execute_reply.started": "2023-12-29T01:37:38.198531Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from numbers import Number\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "from tqdm import trange, tqdm\n",
    "from scipy.io import loadmat\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "from scipy.stats import chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d3cbc6-1ac5-47d6-a0d1-bcbc0be9267e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T01:37:40.756239Z",
     "iopub.status.busy": "2023-12-29T01:37:40.755910Z",
     "iopub.status.idle": "2023-12-29T01:37:40.775993Z",
     "shell.execute_reply": "2023-12-29T01:37:40.775554Z",
     "shell.execute_reply.started": "2023-12-29T01:37:40.756224Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will reload all imports as soon as the code changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0aa91b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T19:57:59.558229Z",
     "start_time": "2023-05-31T19:57:34.292612Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-29T01:37:40.776700Z",
     "iopub.status.busy": "2023-12-29T01:37:40.776556Z",
     "iopub.status.idle": "2023-12-29T01:37:42.855486Z",
     "shell.execute_reply": "2023-12-29T01:37:42.854021Z",
     "shell.execute_reply.started": "2023-12-29T01:37:40.776689Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from constants import DATA_ROOT, RES_ROOT, FIG_ROOT, MIDRES_ROOT\n",
    "from default_paras import def_paras\n",
    "\n",
    "from hdf_utils.data_gen import gen_covs, gen_simu_psd\n",
    "from hdf_utils.fns_sinica import coef_fn, fourier_basis_fn, gen_sini_Xthetas\n",
    "from hdf_utils.likelihood import obt_lin_tm\n",
    "from hdf_utils.SIS_ch import SIS_GLIM\n",
    "from hdf_utils.utils import gen_lam_seq\n",
    "from hdf_utils.hypo_test import  MS2idxs, obt_test_stat_simple2, obt_test_stat_simple3\n",
    "from utils.matrix import col_vec_fn, col_vec2mat_fn, conju_grad, svd_inverse, cholesky_inv\n",
    "from utils.functions import logit_fn\n",
    "from utils.misc import save_pkl, load_pkl\n",
    "from splines import obt_bsp_obasis_Rfn, obt_bsp_basis_Rfn_wrapper\n",
    "from projection import euclidean_proj_l1ball\n",
    "from optimization.cross_validation import CV_err_linear_fn\n",
    "from optimization_ch.opt import optimization, HDF_opt\n",
    "from optimization.opt import optimization as optimization1\n",
    "from optimization.variable_selection import GIC_fn, GCV_fn\n",
    "from penalties.scad_pen import SCAD\n",
    "from models.linear_model import LinearModel\n",
    "from models.logistic_model import LogisticModel\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0a4a46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T19:57:59.621784Z",
     "start_time": "2023-05-31T19:57:59.568097Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-29T01:37:42.858433Z",
     "iopub.status.busy": "2023-12-29T01:37:42.857640Z",
     "iopub.status.idle": "2023-12-29T01:37:42.902098Z",
     "shell.execute_reply": "2023-12-29T01:37:42.901212Z",
     "shell.execute_reply.started": "2023-12-29T01:37:42.858377Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.style.use(FIG_ROOT/\"base.mplstyle\")\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cb5a3d-1ab1-4bc0-bfce-d7ebaedb0391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af2f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd9c6514",
   "metadata": {},
   "source": [
    "# Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d559c-8d6a-428a-bdb9-23c0a5aac96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21e4ccea",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd29f0de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:31:16.397628Z",
     "start_time": "2023-05-31T23:31:16.221812Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-29T01:07:46.712836Z",
     "iopub.status.busy": "2023-12-29T01:07:46.712075Z",
     "iopub.status.idle": "2023-12-29T01:07:46.802511Z",
     "shell.execute_reply": "2023-12-29T01:07:46.801356Z",
     "shell.execute_reply.started": "2023-12-29T01:07:46.712788Z"
    },
    "tags": [
     "param"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29.74717132]\n"
     ]
    }
   ],
   "source": [
    "obt_bsp = obt_bsp_obasis_Rfn\n",
    "#obt_bsp = obt_bsp_basis_Rfn_wrapper\n",
    "np.random.seed(0)\n",
    "paras = edict(def_paras.copy())\n",
    "\n",
    "\n",
    "\n",
    "# Others\n",
    "paras.num_rep = 200 \n",
    "paras.init_noise_sd = -1 # the sd of the noise added to the true value for initial values, if -1, make init 0\n",
    "paras.SIS_ratio = 0.2 # the ratio to keep with SIS procedure\n",
    "#paras.SIS_ratio = 0.2 # the ratio to keep with SIS procedure\n",
    "paras.SIS_pen = 0.02\n",
    "paras.linear_theta_update=\"cholesky_inv\"\n",
    "\n",
    "# candidate sets of tuning parameters, only two \n",
    "# lambda: penalty term\n",
    "# N: num of basis\n",
    "paras.can_lams = [0.01, 0.1, 0.2, 0.3, 0.4, 0.6, 1, 2, 8]\n",
    "paras.can_Ns = [4, 6, 8, 10, 12]\n",
    "\n",
    "\n",
    "# generating dataset\n",
    "paras.n = 200 # num of data obs to be genareted\n",
    "paras.npts = 100 # num of pts to evaluate X(s)\n",
    "paras.freqs = np.linspace(2, 45, paras.npts) # freqs\n",
    "paras.d = 68 # num of ROIs\n",
    "paras.q = 3 # num of other covariates\n",
    "paras.sigma2 = 1 # variance of the error\n",
    "# variance used for estimation, note that the value does not affect any results \n",
    "# as long as I tune the parameter properly\n",
    "paras.norminal_sigma2 = 1 \n",
    "paras.types_ = [\"int\", \"c\", 2]\n",
    "paras.is_std = False\n",
    "\n",
    "# b-spline\n",
    "paras.x = np.linspace(0, 1, paras.npts)\n",
    "paras.basis_mats = []\n",
    "for N in paras.can_Ns:\n",
    "    paras.basis_mats.append(\n",
    "        torch.tensor(obt_bsp(paras.x, N, paras.ord)).to(torch.get_default_dtype())\n",
    "    )\n",
    "paras.SIS_basis_mat = torch.tensor(obt_bsp(paras.x, 8, paras.ord)).to(torch.get_default_dtype())\n",
    "\n",
    "# True parameters\n",
    "paras.alp_GT = np.array([5, -1, 2])\n",
    "# fourier basis\n",
    "cs = [0.0, 0.0, 0.0] # for sinica paper\n",
    "paras.fourier_basis = fourier_basis_fn(paras.x)[:, :]\n",
    "paras.fourier_basis_coefs = ([cs[0]*coef_fn(0.2), cs[1]*coef_fn(0.2), cs[2]*coef_fn(0.2)] + \n",
    "                             [np.zeros(50)] * (paras.d-3-1) +\n",
    "                             [coef_fn(0.2)]\n",
    "                             )\n",
    "paras.fourier_basis_coefs = np.array(paras.fourier_basis_coefs).T \n",
    "paras.beta_GT = paras.fourier_basis @ paras.fourier_basis_coefs * 2\n",
    "beta_GT_norm = np.linalg.norm(paras.beta_GT, axis=0)\n",
    "print(beta_GT_norm[beta_GT_norm!=0])\n",
    "\n",
    "paras.Gam_GT_ests = [(np.linalg.inv(basis_mat.numpy().T \n",
    "                                  @ basis_mat.numpy()) \n",
    "                                  @ basis_mat.numpy().T \n",
    "                                  @ paras.beta_GT) \n",
    "                     for basis_mat in paras.basis_mats]\n",
    "\n",
    "# optimization\n",
    "# not used, to use it, you have to know GT\n",
    "Rmins = [(2*(np.linalg.norm(paras.Gam_GT_ests[ix]\n",
    "                            /np.sqrt(paras.can_Ns[ix]), axis=0).sum() \n",
    "           + np.abs(paras.alp_GT).sum())) \n",
    "        for ix in range(len(paras.can_Ns))]\n",
    "paras.Rmin = np.max(Rmins)/5\n",
    "paras.Rmin = 100000\n",
    "paras.Rfct = 2\n",
    "paras.stop_cv = 5e-4\n",
    "paras.max_iter = 2000\n",
    "paras.beta = 1.2 # default is 1, but will make a lot of iteration non-conv\n",
    "\n",
    "# CV\n",
    "paras.cv_is_center = True\n",
    "paras.cv_SIS_ratio = paras.SIS_ratio\n",
    "paras.cv_SIS_pen = paras.SIS_pen\n",
    "paras.cv_SIS_basis_mat = paras.SIS_basis_mat\n",
    "paras.num_cv_fold = 5\n",
    "paras.cv_init_noise_sd = paras.init_noise_sd\n",
    "\n",
    "\n",
    "# hypothesis test\n",
    "#without loss of generality, we assume the idxs in M is the first m betas\n",
    "paras.sel_idx = np.arange(3, paras.d) # M^c set, \n",
    "paras.M_idxs = np.delete(np.arange(paras.d), paras.sel_idx) # the M set\n",
    "paras.Cmats = [\n",
    "    np.array([[1, 0, 0], [0, 1, -1]])\n",
    "    #np.array([1, -1]).reshape(1, 2), # m x m I matrix, [beta1, beta2] = [0, 0]\n",
    "    #np.eye(len(paras.M_idxs)), # m x m I matrix, [beta1, beta2] = [0, 0]\n",
    "]\n",
    "paras.svdinv_eps_Q = 1e-7 # now 0 means inverse, small value like 0.01 means remove small eig vals.\n",
    "paras.svdinv_eps_Psi = 1e-7 \n",
    "\n",
    "\n",
    "# saving path\n",
    "paras.save_dir = RES_ROOT/\"test\"\n",
    "if not paras.save_dir.exists():\n",
    "    paras.save_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd898ca-898f-4507-b585-65c04b98a9ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b081ea-9f16-4275-b1ef-044fa433b439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66c2f90f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T18:09:55.509389Z",
     "start_time": "2022-12-08T18:09:55.343396Z"
    }
   },
   "source": [
    "## Fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5567c-6bab-438d-971c-0e40b0c4c53d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:31:24.456489Z",
     "start_time": "2023-05-31T23:31:24.440199Z"
    },
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60faf838-bab1-4889-9f15-bed1fadfda82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T01:07:48.271201Z",
     "iopub.status.busy": "2023-12-29T01:07:48.270268Z",
     "iopub.status.idle": "2023-12-29T01:07:48.320308Z",
     "shell.execute_reply": "2023-12-29T01:07:48.319600Z",
     "shell.execute_reply.started": "2023-12-29T01:07:48.271116Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _is_exists(tmp_paras):\n",
    "    \"\"\"\n",
    "    Check if a file with the given parameters exists.\n",
    "\n",
    "    Args:\n",
    "    tmp_paras:\n",
    "        d (int): The value of d in the file name.\n",
    "        n (int): The value of n in the file name.\n",
    "        npts:\n",
    "        is_std\n",
    "        seed (int): The seed value in the file name.\n",
    "\n",
    "    Returns:\n",
    "    bool or Path: Returns the file path if the file exists, otherwise returns False.\n",
    "    \"\"\"\n",
    "    _get_n = lambda fil: int(fil.stem.split(\"_\")[2].split(\"-\")[-1])\n",
    "    fils = MIDRES_ROOT.glob(f\"PSD_d-{tmp_paras.d}_n-*npts-{tmp_paras.npts}_is_std-{tmp_paras.is_std}\")\n",
    "    # We do not need fil with n as we know the data with corresponding seed does not exist\n",
    "    fils = [fil for fil in fils if _get_n(fil) !=tmp_paras.n]\n",
    "    if len(fils) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        fils = sorted(fils, key=_get_n)\n",
    "        ns = np.array([_get_n(fil) for fil in fils])\n",
    "        idxs = np.where(tmp_paras.n <= ns)[0]\n",
    "        if len(idxs) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            fil =fils[idxs[0]]\n",
    "            path = MIDRES_ROOT/fil/f\"seed_{tmp_paras.seed}.pkl\"\n",
    "            return path if path.exists() else False\n",
    "def _get_filename(params):\n",
    "    keys = [\"d\", \"n\", \"npts\", \"is_std\"]\n",
    "    folder_name = 'PSD_'+'_'.join(f\"{k}-{params[k]}\" for k in keys)\n",
    "    return folder_name + f'/seed_{params.seed}.pkl'\n",
    "def _gen_simu_data_all(seed, paras, verbose=False, is_gen=False):\n",
    "    \"\"\"\n",
    "    Generate simulated data for all parameters.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed for random number generator.\n",
    "        paras (dict): Dictionary containing the following parameters:\n",
    "            - n (int): Number of samples.\n",
    "            - d (int): Number of dimensions.\n",
    "            - q (int): Number of covariates.\n",
    "            - types_ (list): List of types for generating covariates.\n",
    "            - alp_GT (list): List of ground truth alpha values.\n",
    "            - beta_GT (list): List of ground truth beta values.\n",
    "            - freqs (list): List of frequencies for generating simulated PSD.\n",
    "            - sigma2 (float): Variance of the noise.\n",
    "        verbose(bool): Verbose or not\n",
    "        is_gen(bool): Only for generating or not. If True, only checking or generating X, not return anything.\n",
    "\n",
    "    Returns:\n",
    "        all_data (dict): Dictionary containing the following simulated data:\n",
    "            - X (torch.Tensor): Tensor of shape (n, d, npts) containing the simulated PSD.\n",
    "            - Y (torch.Tensor): Tensor of shape (n,) containing the response variable.\n",
    "            - Z (torch.Tensor): Tensor of shape (n, q) containing the covariates.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    _paras = edict(paras.copy())\n",
    "    # simulated PSD\n",
    "    assert len(_paras.types_) == _paras.q\n",
    "    assert len(_paras.alp_GT) == _paras.q\n",
    "    tmp_paras = edict()\n",
    "    tmp_paras.seed = seed \n",
    "    tmp_paras.n = _paras.n\n",
    "    tmp_paras.d = _paras.d\n",
    "    tmp_paras.npts = _paras.npts\n",
    "    tmp_paras.is_std = _paras.is_std\n",
    "    con_idxs = [typ ==\"c\" for typ in _paras.types_]\n",
    "    \n",
    "    file_path = MIDRES_ROOT/_get_filename(tmp_paras)\n",
    "    if file_path.exists():\n",
    "        if is_gen:\n",
    "            return None\n",
    "        simu_curvs = load_pkl(file_path, verbose=verbose)\n",
    "    else:\n",
    "        ofil =  _is_exists(tmp_paras)\n",
    "        if ofil:\n",
    "            if is_gen:\n",
    "                return None\n",
    "            simu_curvs = load_pkl(ofil, verbose=verbose)\n",
    "        else:\n",
    "            if _paras.is_std:\n",
    "                simu_curvs = gen_simu_psd(_paras.n, _paras.d, _paras.freqs, prior_sd=10, n_jobs=28, is_prog=False, is_std=_paras.is_std)\n",
    "            else:\n",
    "                simu_curvs = gen_simu_psd(_paras.n, _paras.d, _paras.freqs, prior_sd=10, n_jobs=28, is_prog=False, is_std=_paras.is_std)\n",
    "                simu_curvs = simu_curvs - simu_curvs.mean(axis=-1, keepdims=True); # not std, but center it\n",
    "            save_pkl(file_path, simu_curvs, verbose=verbose)\n",
    "    if is_gen:\n",
    "        return None\n",
    "    simu_curvs = simu_curvs[:_paras.n]\n",
    "    simu_curvs = (simu_curvs + np.random.randn(*simu_curvs.shape)*10)*1 # larger\n",
    "    #simu_curvs = np.random.randn(_paras.n, _paras.d, _paras.npts)* 10\n",
    "    simu_covs = gen_covs(_paras.n, _paras.types_)\n",
    "    \n",
    "    # linear term and Y\n",
    "    int_part = np.sum(_paras.beta_GT.T* simu_curvs[:, :, :], axis=1).mean(axis=1)\n",
    "    cov_part = simu_covs @ _paras.alp_GT \n",
    "    \n",
    "    # linear term\n",
    "    lin_term = cov_part + int_part\n",
    "    \n",
    "    # Y \n",
    "    errs_raw = np.random.standard_t(df=3, size=paras.n)                                                                                                                                                   \n",
    "    errs = np.sqrt(_paras.sigma2)*(errs_raw - errs_raw.mean())/errs_raw.std()\n",
    "    Y = lin_term + errs\n",
    "    #Y = lin_term + np.random.randn(_paras.n)*np.sqrt(_paras.sigma2)\n",
    "    \n",
    "    # center\n",
    "    X_centered = simu_curvs - simu_curvs.mean(axis=0, keepdims=True)\n",
    "    Y_centered = Y - Y.mean(axis=0, keepdims=True)\n",
    "    # this step is not necessary for simulation as I did so in generating data step                          \n",
    "    # but for real data, plz do this\n",
    "    Z_std = simu_covs.copy()\n",
    "    Z_std[:, con_idxs] = ((simu_covs[:, con_idxs] - simu_covs[:, con_idxs].mean(axis=0, keepdims=True))\n",
    "                          /simu_covs[:, con_idxs].std(axis=0, keepdims=True))\n",
    "    \n",
    "    # To torch\n",
    "    X = torch.Tensor(X_centered) # n x d x npts\n",
    "    Z = torch.Tensor(Z_std) # n x q\n",
    "    Y = torch.Tensor(Y_centered)\n",
    "    \n",
    "    all_data = edict()\n",
    "    all_data.X = X\n",
    "    all_data.Y = Y\n",
    "    all_data.Z = Z\n",
    "    all_data.lin_term = lin_term\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd3e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4043966",
   "metadata": {},
   "source": [
    "## Simu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841c5ae-4cea-4a4d-aafa-c8c901587caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7a35dfb-755c-476d-b092-28c0875ef5e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T01:09:10.520467Z",
     "iopub.status.busy": "2023-12-29T01:09:10.519818Z",
     "iopub.status.idle": "2023-12-29T01:09:10.849181Z",
     "shell.execute_reply": "2023-12-29T01:09:10.848738Z",
     "shell.execute_reply.started": "2023-12-29T01:09:10.520420Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 17:09:10,771 - optimization_ch.opt - INFO - The paras is {'stop_cv': 0.0005, 'max_iter': 2000, 'inner_loop_verbose': 0, 'alpha': 0.9, 'beta': 1.2, 'R': 100000, 'N_eps': 0.0001, 'N_maxit': 100, 'is_BFGS': 'adaptive', 'linear_theta_update': 'cholesky_inv', 'linear_mat': None, 'q': 3, 'N': 8}.\n",
      "  2%|██▏                                                                                                | 43/2000 [00:00<00:03, 611.13it/s, error=0.00076, GamL0=14, CV=0.0005]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<optimization_ch.one_step_opt.OneStepOpt at 0x7f0037efb280>, (44, 2000))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "N = 8\n",
    "lam = 0.5\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "        \n",
    "_paras = edict(paras.copy())\n",
    "_paras.Rv = 100000\n",
    "_paras.R = 100000\n",
    "_paras.seed = seed\n",
    "_paras.lam = lam\n",
    "_paras.N = N\n",
    "_paras.basis_mat = _paras.basis_mats[_paras.can_Ns.index(N)]\n",
    "_paras.Gam_GT_est = paras.Gam_GT_ests[_paras.can_Ns.index(N)]\n",
    "cur_data = _gen_simu_data_all(_paras.seed, _paras)\n",
    "    \n",
    "    \n",
    "    \n",
    "# do sure independent screening for dim reduction\n",
    "if _paras.SIS_ratio < 1:\n",
    "    keep_idxs, _ = SIS_GLIM(Y=cur_data.Y, X=cur_data.X, Z=cur_data.Z, \n",
    "                             basis_mat=_paras.SIS_basis_mat, \n",
    "                             keep_ratio=_paras.SIS_ratio, \n",
    "                             model_type=\"linear\", \n",
    "                             SIS_pen=_paras.SIS_pen, \n",
    "                             sel_idx=_paras.sel_idx)\n",
    "else:\n",
    "    keep_idxs = _paras.sel_idx\n",
    "M_idxs = np.delete(np.arange(_paras.d), _paras.sel_idx)\n",
    "_paras.keep_idxs = np.sort(np.concatenate([M_idxs, keep_idxs]))\n",
    "    \n",
    "_paras.sel_idx_SIS = np.where(np.array([keep_idx in _paras.sel_idx for keep_idx in _paras.keep_idxs]))[0]\n",
    "_paras.d_SIS = len(_paras.keep_idxs)\n",
    "\n",
    "cur_data_SIS = edict(cur_data.copy())\n",
    "cur_data_SIS.X = cur_data.X[:, _paras.keep_idxs, :]\n",
    "\n",
    "\n",
    "if _paras.init_noise_sd < 0:\n",
    "    alp_init = torch.zeros(_paras.q)\n",
    "    Gam_init = torch.zeros(_paras.N, _paras.d_SIS)\n",
    "    theta_init = torch.cat([alp_init, col_vec_fn(Gam_init)/np.sqrt(_paras.N)])\n",
    "    rhok_init = torch.zeros(_paras.d_SIS*_paras.N)\n",
    "else:\n",
    "    alp_init = torch.Tensor(_paras.alp_GT) + torch.randn(_paras.q)*_paras.init_noise_sd\n",
    "    Gam_init = torch.Tensor(_paras.Gam_GT_est[:, _paras.keep_idxs]) + torch.randn(_paras.N, _paras.d_SIS)*_paras.init_noise_sd\n",
    "    theta_init = torch.cat([alp_init, col_vec_fn(Gam_init)/np.sqrt(_paras.N)])\n",
    "    rhok_init = torch.randn(_paras.d_SIS*_paras.N)\n",
    "    \n",
    "model = LinearModel(Y=cur_data_SIS.Y, \n",
    "                    X=cur_data_SIS.X, \n",
    "                    Z=cur_data_SIS.Z, \n",
    "                    basis_mat=_paras.basis_mat, \n",
    "                    sigma2=_paras.norminal_sigma2)\n",
    "# 3e0\n",
    "pen = SCAD(lams=_paras.lam, a=_paras.a,  sel_idx=_paras.sel_idx_SIS)\n",
    "    \n",
    "\n",
    "#main_res1 = optimization1(model=model, \n",
    "#                         penalty=pen, \n",
    "#                         inits=[alp_init, Gam_init, theta_init, rhok_init],\n",
    "#                         is_prg=True,\n",
    "#                         save_paras=False,    \n",
    "#                         input_paras=_paras)\n",
    "main_res = optimization(model=model, \n",
    "                        penalty=pen, \n",
    "                        inits=[Gam_init, theta_init, rhok_init],\n",
    "                        verbose=2,\n",
    "                        alpha=_paras.alpha,\n",
    "                        beta=_paras.beta, \n",
    "                        R = _paras.R,\n",
    "                        stop_cv=_paras.stop_cv,\n",
    "                        max_iter=_paras.max_iter,\n",
    "                        linear_mat=None, \n",
    "                        linear_theta_update=_paras.linear_theta_update,\n",
    "                        inner_loop_verbose=0, \n",
    "                       )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adbae0b4-6c0f-4e83-ac9c-e7c435c15445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T01:36:46.014287Z",
     "iopub.status.busy": "2023-12-29T01:36:46.013616Z",
     "iopub.status.idle": "2023-12-29T01:36:46.280718Z",
     "shell.execute_reply": "2023-12-29T01:36:46.280177Z",
     "shell.execute_reply.started": "2023-12-29T01:36:46.014241Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 17:36:46,128 - optimization_ch.opt - INFO - opt parmas is {'stop_cv': 0.0005, 'max_iter': 2000, 'inner_loop_verbose': 0, 'alpha': 0.9, 'beta': 1.2, 'R': 100000.0, 'N_eps': 0.0001, 'N_maxit': 100, 'is_BFGS': 'adaptive', 'linear_theta_update': 'cholesky_inv', 'linear_mat': None, 'is_full': False}.\n",
      "2023-12-28 17:36:46,130 - optimization_ch.opt - INFO - SIS parmas is {'SIS_ratio': 0.2, 'SIS_pen': 0.02, 'SIS_basis_N': 8, 'SIS_basis_ord': 4}.\n",
      "2023-12-28 17:36:46,131 - optimization_ch.opt - INFO - model parmas is {'norminal_sigma2': 1}.\n",
      "2023-12-28 17:36:46,131 - optimization_ch.opt - INFO - As cov_types is not provided, inferring the continuous covariates.\n",
      "2023-12-28 17:36:46,202 - optimization_ch.opt - INFO - The paras is {'stop_cv': 0.0005, 'max_iter': 2000, 'inner_loop_verbose': 0, 'alpha': 0.9, 'beta': 1.2, 'R': 100000.0, 'N_eps': 0.0001, 'N_maxit': 100, 'is_BFGS': 'adaptive', 'linear_theta_update': 'cholesky_inv', 'linear_mat': None, 'q': 3, 'N': 8}.\n",
      "  2%|██▏                                                                                                | 43/2000 [00:00<00:03, 593.88it/s, error=0.00076, GamL0=14, CV=0.0005]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<optimization_ch.one_step_opt.OneStepOpt at 0x7f00b6842490>, (44, 2000))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_res2 = HDF_opt(X=cur_data.X, Y=cur_data.Y, Z=cur_data.Z, is_std=True, \n",
    "        SIS_ratio=_paras.SIS_ratio, lam=lam, N=N, sel_idx=_paras.sel_idx, opt_params={\"beta\":1.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "596ef8e9-c868-4054-9612-bebd080e3b0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T01:36:48.776956Z",
     "iopub.status.busy": "2023-12-29T01:36:48.776309Z",
     "iopub.status.idle": "2023-12-29T01:36:48.820082Z",
     "shell.execute_reply": "2023-12-29T01:36:48.819273Z",
     "shell.execute_reply.started": "2023-12-29T01:36:48.776891Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4211e-14,  4.4270e-15, -4.1217e-15,  0.0000e+00,  1.5266e-15,\n",
       "          2.5206e-15, -2.4078e-15,  3.5705e-15,  1.7686e-15, -1.9880e-15,\n",
       "         -1.6202e-15,  3.8997e-15,  3.2301e-15,  0.0000e+00, -6.8695e-16,\n",
       "         -1.0436e-14],\n",
       "        [ 3.7748e-15, -1.0408e-16, -5.4123e-16,  0.0000e+00,  3.8580e-15,\n",
       "          1.4728e-15,  2.6021e-15,  1.2334e-15,  1.0619e-15,  7.0430e-16,\n",
       "         -6.1409e-16, -3.6984e-15,  1.0825e-15,  0.0000e+00, -2.8172e-15,\n",
       "         -1.1324e-14],\n",
       "        [ 6.5547e-15, -4.8984e-15,  1.2768e-15,  0.0000e+00, -1.4710e-15,\n",
       "         -1.2262e-16,  9.7838e-16, -1.8319e-15,  1.1419e-15,  6.9389e-17,\n",
       "          7.6675e-16,  1.5613e-15, -1.2351e-15,  0.0000e+00,  2.1684e-16,\n",
       "         -2.2760e-15],\n",
       "        [-4.8850e-15, -5.8287e-16, -6.9389e-16,  0.0000e+00,  5.7593e-16,\n",
       "         -3.4851e-15, -1.7070e-15,  2.8623e-16, -3.3307e-15, -4.7184e-16,\n",
       "         -1.4710e-15,  1.5717e-15, -7.2858e-17,  0.0000e+00,  1.9221e-15,\n",
       "          2.2204e-15],\n",
       "        [-2.9837e-15,  5.5511e-16,  2.2413e-15,  0.0000e+00, -1.5266e-16,\n",
       "         -2.5292e-15,  2.4980e-16, -6.4358e-16, -4.7640e-16, -3.8511e-16,\n",
       "         -9.2808e-17, -1.0825e-15,  1.4225e-15,  0.0000e+00, -7.9450e-16,\n",
       "          1.7764e-15],\n",
       "        [-1.6341e-15,  5.5650e-15,  3.5735e-16,  0.0000e+00,  7.9797e-16,\n",
       "          1.5743e-15, -6.2450e-17, -7.4593e-16, -1.5751e-15,  1.0894e-15,\n",
       "          4.8139e-16,  2.3453e-15, -2.4009e-15,  0.0000e+00, -3.9118e-16,\n",
       "          4.1078e-15],\n",
       "        [ 1.3739e-15,  6.1548e-15,  6.3838e-16,  0.0000e+00, -2.3453e-15,\n",
       "          4.3065e-16, -9.2461e-16,  1.5266e-16,  1.4134e-15, -2.2204e-16,\n",
       "         -6.8695e-16,  6.6266e-16,  1.3739e-15,  0.0000e+00, -1.5179e-16,\n",
       "          4.2188e-15],\n",
       "        [ 8.8818e-16, -2.0817e-17,  1.1796e-15,  0.0000e+00,  2.8866e-15,\n",
       "         -2.0331e-15,  6.0715e-16,  5.2042e-16, -9.6581e-16,  3.0531e-16,\n",
       "         -1.1380e-15,  1.0131e-15,  4.0246e-16,  0.0000e+00,  1.0443e-15,\n",
       "          1.9984e-15]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_res[0].Gamk- main_res2[0].Gamk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8cc7f9-0859-4a43-a1bf-09b1700c4333",
   "metadata": {},
   "source": [
    "# Logi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d32b76-2ef7-4e53-a7af-d08802923647",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T01:37:46.791237Z",
     "iopub.status.busy": "2023-12-29T01:37:46.790556Z",
     "iopub.status.idle": "2023-12-29T01:37:46.989523Z",
     "shell.execute_reply": "2023-12-29T01:37:46.987143Z",
     "shell.execute_reply.started": "2023-12-29T01:37:46.791183Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         29.74717132]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "obt_bsp = obt_bsp_obasis_Rfn\n",
    "#obt_bsp = obt_bsp_basis_Rfn_wrapper\n",
    "paras = edict(def_paras.copy())\n",
    "\n",
    "\n",
    "\n",
    "# Others\n",
    "paras.num_rep = 200 \n",
    "paras.init_noise_sd = -1 # the sd of the noise added to the true value for initial values, if -1, make init 0\n",
    "paras.SIS_ratio = 0.20 # the ratio to keep with SIS procedure\n",
    "paras.SIS_pen = 0.02 \n",
    "paras.linear_theta_update=\"cholesky_inv\"\n",
    "\n",
    "# candidate sets of tuning parameters, only two \n",
    "# lambda: penalty term\n",
    "# N: num of basis\n",
    "paras.can_lams = [0.01, 0.1, 0.2, 0.3, 0.4, 0.6, 1, 2, 8] # for non\n",
    "paras.can_lams = [0.001, 0.3, 0.6, 0.8, 1, 1.2, 1.4, 2, 16] # for orthogonal basis\n",
    "paras.can_Ns = [4, 6, 8, 10, 12]\n",
    "\n",
    "\n",
    "# generating dataset\n",
    "paras.n = 200 # num of data obs to be genareted\n",
    "paras.npts = 100 # num of pts to evaluate X(s)\n",
    "paras.d = 68 # num of ROIs\n",
    "paras.q = 3 # num of other covariates\n",
    "paras.types_ = [\"int\", \"c\", 2]\n",
    "paras.is_std = False # std PSD or not\n",
    "\n",
    "\n",
    "# b-spline\n",
    "paras.x = np.linspace(0, 1, paras.npts)\n",
    "paras.basis_mats = []\n",
    "for N in paras.can_Ns:\n",
    "    paras.basis_mats.append(\n",
    "        torch.tensor(obt_bsp(paras.x, N, paras.ord)).to(torch.get_default_dtype())\n",
    "    )\n",
    "paras.SIS_basis_mat = torch.tensor(obt_bsp(paras.x, 8, paras.ord)).to(torch.get_default_dtype())\n",
    "\n",
    "# True parameters\n",
    "# Need to adaptively change intercept for each setting\n",
    "# to make such 1 and 0 is balanced\n",
    "paras.alp_GT0 = np.array([-1.0, 2.0]) # not include intercept\n",
    "#paras.alp_GT0 = np.array([-1, 2]) # not include intercept\n",
    "paras.intercept_cans = np.linspace(-30, 1, 20) \n",
    "# fourier basis\n",
    "cs = [0.0, 0.0, 0.0] # for sinica paper\n",
    "paras.fourier_basis = fourier_basis_fn(paras.x)[:, :]\n",
    "paras.fourier_basis_coefs = ([cs[0]*coef_fn(0.2), cs[1]*coef_fn(0.2), cs[2]*coef_fn(0.2)] + \n",
    "                             [np.zeros(50)] * (paras.d-3-1) +\n",
    "                             [coef_fn(0.2)]\n",
    "                             )\n",
    "paras.fourier_basis_coefs = np.array(paras.fourier_basis_coefs).T \n",
    "paras.beta_GT = paras.fourier_basis @ paras.fourier_basis_coefs * 2 \n",
    "print(np.linalg.norm(paras.beta_GT, axis=0))\n",
    "\n",
    "paras.Gam_GT_ests = [(np.linalg.inv(basis_mat.numpy().T \n",
    "                                  @ basis_mat.numpy()) \n",
    "                                  @ basis_mat.numpy().T \n",
    "                                  @ paras.beta_GT) \n",
    "                     for basis_mat in paras.basis_mats]\n",
    "\n",
    "# optimization\n",
    "# not used, to use it, you have to know GT\n",
    "#Rmins = [(2*(np.linalg.norm(paras.Gam_GT_ests[ix]\n",
    "#                            /np.sqrt(paras.can_Ns[ix]), axis=0).sum() \n",
    "#           + np.abs(paras.alp_GT0).sum()+10)) \n",
    "#        for ix in range(len(paras.can_Ns))]\n",
    "#paras.Rmin = np.max(Rmins)\n",
    "paras.Rmin = 100000\n",
    "paras.Rfct = 2\n",
    "paras.stop_cv = 5e-4\n",
    "paras.max_iter = 2000\n",
    "paras.num_cv_fold = 5\n",
    "\n",
    "paras.N_eps = 1e-4 # the stop criteria for Newton-Ralpson method, only for logistic model\n",
    "paras.N_maxit = 100\n",
    "paras.is_BFGS = \"adaptive\"\n",
    "\n",
    "paras.cv_is_center = True\n",
    "paras.cv_SIS_ratio = paras.SIS_ratio\n",
    "paras.cv_SIS_pen = paras.SIS_pen\n",
    "paras.cv_SIS_basis_mat = paras.SIS_basis_mat\n",
    "paras.num_cv_fold = 5\n",
    "paras.cv_init_noise_sd = paras.init_noise_sd\n",
    "\n",
    "\n",
    "# hypothesis test\n",
    "#without loss of generality, we assume the idxs in M is the first m betas\n",
    "paras.sel_idx = np.arange(1, paras.d) # M^c set, \n",
    "paras.M_idxs = np.delete(np.arange(paras.d), paras.sel_idx) # the M set\n",
    "paras.Cmats = [\n",
    "    np.eye(len(paras.M_idxs)), # m x m I matrix, [beta1, beta2] = [0, 0]\n",
    "    #np.array([1, -1]).reshape(1, -1), # beta1-beta2=0\n",
    "]\n",
    "paras.svdinv_eps_Q = 1e-7 # now 0 means inverse, small value like 0.01 means remove small eig vals.\n",
    "paras.svdinv_eps_Psi = 1e-7\n",
    "\n",
    "paras.save_dir = RES_ROOT/\"simu_linear_sinica_samebetaX_tmp\"\n",
    "if not paras.save_dir.exists():\n",
    "    paras.save_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b57f85af-dbd0-4700-81f5-458d9b66cc2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T01:37:47.358711Z",
     "iopub.status.busy": "2023-12-29T01:37:47.358149Z",
     "iopub.status.idle": "2023-12-29T01:37:47.416834Z",
     "shell.execute_reply": "2023-12-29T01:37:47.415772Z",
     "shell.execute_reply.started": "2023-12-29T01:37:47.358667Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _is_exists(tmp_paras):\n",
    "    \"\"\"\n",
    "    Check if a file with the given parameters exists.\n",
    "\n",
    "    Args:\n",
    "    tmp_paras:\n",
    "        d (int): The value of d in the file name.\n",
    "        n (int): The value of n in the file name.\n",
    "        npts:\n",
    "        is_std\n",
    "        seed (int): The seed value in the file name.\n",
    "\n",
    "    Returns:\n",
    "    bool or Path: Returns the file path if the file exists, otherwise returns False.\n",
    "    \"\"\"\n",
    "    _get_n = lambda fil: int(fil.stem.split(\"_\")[2].split(\"-\")[-1])\n",
    "    fils = MIDRES_ROOT.glob(f\"PSD_d-{tmp_paras.d}_n-*npts-{tmp_paras.npts}_is_std-{tmp_paras.is_std}\")\n",
    "    # We do not need fil with n as we know the data with corresponding seed does not exist\n",
    "    fils = [fil for fil in fils if _get_n(fil) !=tmp_paras.n]\n",
    "    if len(fils) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        fils = sorted(fils, key=_get_n)\n",
    "        ns = np.array([_get_n(fil) for fil in fils])\n",
    "        idxs = np.where(tmp_paras.n <= ns)[0]\n",
    "        if len(idxs) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            fil =fils[idxs[0]]\n",
    "            path = MIDRES_ROOT/fil/f\"seed_{tmp_paras.seed}.pkl\"\n",
    "            return path if path.exists() else False\n",
    "def _get_filename(params):\n",
    "    keys = [\"d\", \"n\", \"npts\", \"is_std\"]\n",
    "    folder_name = 'PSD_'+'_'.join(f\"{k}-{params[k]}\" for k in keys)\n",
    "    return folder_name + f'/seed_{params.seed}.pkl'\n",
    "def _gen_simu_data_all1(seed, paras, verbose=False, is_gen=False):\n",
    "    \"\"\"\n",
    "    Generate simulated data for all parameters.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed for random number generator.\n",
    "        paras (dict): Dictionary containing the following parameters:\n",
    "            - n (int): Number of samples.\n",
    "            - d (int): Number of dimensions.\n",
    "            - q (int): Number of covariates.\n",
    "            - types_ (list): List of types for generating covariates.\n",
    "            - alp_GT (list): List of ground truth alpha values.\n",
    "            - beta_GT (list): List of ground truth beta values.\n",
    "            - freqs (list): List of frequencies for generating simulated PSD.\n",
    "            - sigma2 (float): Variance of the noise.\n",
    "        verbose(bool): Verbose or not\n",
    "        is_gen(bool): Only for generating or not. If True, only checking or generating X, not return anything.\n",
    "\n",
    "    Returns:\n",
    "        all_data (dict): Dictionary containing the following simulated data:\n",
    "            - X (torch.Tensor): Tensor of shape (n, d, npts) containing the simulated PSD.\n",
    "            - Y (torch.Tensor): Tensor of shape (n,) containing the response variable.\n",
    "            - Z (torch.Tensor): Tensor of shape (n, q) containing the covariates.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    _paras = edict(paras.copy())\n",
    "    # simulated PSD\n",
    "    assert len(_paras.types_) == _paras.q\n",
    "    assert len(_paras.alp_GT) == _paras.q\n",
    "    con_idxs = [typ ==\"c\" for typ in _paras.types_]\n",
    "    tmp_paras = edict()\n",
    "    tmp_paras.seed = seed \n",
    "    tmp_paras.n = _paras.n\n",
    "    tmp_paras.d = _paras.d\n",
    "    tmp_paras.npts = _paras.npts\n",
    "    tmp_paras.is_std = _paras.is_std\n",
    "    \n",
    "    file_path = MIDRES_ROOT/_get_filename(tmp_paras)\n",
    "    if file_path.exists():\n",
    "        if is_gen:\n",
    "            return None\n",
    "        simu_curvs = load_pkl(file_path, verbose=verbose)\n",
    "    else:\n",
    "        ofil =  _is_exists(tmp_paras)\n",
    "        if ofil:\n",
    "            if is_gen:\n",
    "                return None\n",
    "            simu_curvs = load_pkl(ofil, verbose=verbose)\n",
    "        else:\n",
    "            if _paras.is_std:\n",
    "                simu_curvs = gen_simu_psd(_paras.n, _paras.d, _paras.freqs, prior_sd=10, n_jobs=28, is_prog=False, is_std=_paras.is_std)\n",
    "            else:\n",
    "                simu_curvs = gen_simu_psd(_paras.n, _paras.d, _paras.freqs, prior_sd=10, n_jobs=28, is_prog=False, is_std=_paras.is_std)\n",
    "                simu_curvs = simu_curvs - simu_curvs.mean(axis=-1, keepdims=True); # not std, but center it\n",
    "            save_pkl(file_path, simu_curvs, verbose=verbose)\n",
    "    if is_gen:\n",
    "        return None\n",
    "    simu_curvs = simu_curvs[:_paras.n]\n",
    "    simu_curvs = (simu_curvs + np.random.randn(*simu_curvs.shape)*10)*1 # larger\n",
    "    #simu_curvs = np.random.randn(_paras.n, _paras.d, _paras.npts)* 10\n",
    "    simu_covs = gen_covs(_paras.n, _paras.types_)\n",
    "    \n",
    "    # linear term and Y\n",
    "    int_part = np.sum(_paras.beta_GT.T* simu_curvs[:, :, :], axis=1).mean(axis=1)\n",
    "    cov_part = simu_covs @ _paras.alp_GT \n",
    "    \n",
    "    # linear term\n",
    "    lin_term = cov_part + int_part\n",
    "    probs = logit_fn(lin_term)\n",
    "    \n",
    "    # Y \n",
    "    Y = np.random.binomial(1, probs, size=len(probs))\n",
    "    \n",
    "    # center\n",
    "    X_centered = simu_curvs - simu_curvs.mean(axis=0, keepdims=True)\n",
    "    # this step is not necessary for simulation as I did so in generating data step\n",
    "    # but for real data, plz do this\n",
    "    Z_std = simu_covs.copy()\n",
    "    Z_std[:, con_idxs] = ((simu_covs[:, con_idxs] - simu_covs[:, con_idxs].mean(axis=0, keepdims=True))\n",
    "                          /simu_covs[:, con_idxs].std(axis=0, keepdims=True))\n",
    "    \n",
    "    \n",
    "    # To torch\n",
    "    X = torch.Tensor(X_centered) # n x d x npts\n",
    "    Z = torch.Tensor(Z_std) # n x q\n",
    "    Y = torch.Tensor(Y)\n",
    "    \n",
    "    all_data = edict()\n",
    "    all_data.X = X\n",
    "    all_data.Y = Y\n",
    "    all_data.Z = Z\n",
    "    all_data.lin_term = lin_term\n",
    "    all_data.cov_part = cov_part \n",
    "    all_data.int_part = int_part\n",
    "    all_data.simu_curvs = simu_curvs\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6285ab5c-5e7c-4c4b-96c0-cc8c67fdb510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T01:38:03.017868Z",
     "iopub.status.busy": "2023-12-29T01:38:03.017226Z",
     "iopub.status.idle": "2023-12-29T01:38:16.557895Z",
     "shell.execute_reply": "2023-12-29T01:38:16.556909Z",
     "shell.execute_reply.started": "2023-12-29T01:38:03.017822Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:13<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of Y is 0.435 under intercept -7.158.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ress = []\n",
    "for inte in tqdm(paras.intercept_cans):\n",
    "    tmp_paras = edict(paras.copy())\n",
    "    tmp_paras.alp_GT = np.concatenate([[inte], paras.alp_GT0])\n",
    "    _run_fn = lambda seed: _gen_simu_data_all1(seed, tmp_paras).Y.numpy()\n",
    "    with Parallel(n_jobs=20) as parallel:\n",
    "        res = parallel(delayed(_run_fn)(seed) for seed in range(100))\n",
    "    ress.append(np.array(res))\n",
    "    \n",
    "# get the intercept\n",
    "Yms = np.array([res.mean() for res in ress])\n",
    "intercept = paras.intercept_cans[np.argmin(np.abs(Yms-0.5))]\n",
    "paras.alp_GT = np.concatenate([[intercept], paras.alp_GT0])\n",
    "print(f\"The mean of Y is {Yms[np.argmin(np.abs(Yms-0.5))]:.3f} under intercept {intercept:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b80134e-355e-4cf0-80b0-903e1b77ff88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3939b6f8-eff8-4df4-9967-6136e6e33674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T01:44:35.817495Z",
     "iopub.status.busy": "2023-12-29T01:44:35.816699Z",
     "iopub.status.idle": "2023-12-29T01:44:37.719600Z",
     "shell.execute_reply": "2023-12-29T01:44:37.719041Z",
     "shell.execute_reply.started": "2023-12-29T01:44:35.817445Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 17:44:36,220 - optimization_ch.opt - INFO - The paras is {'stop_cv': 0.0005, 'max_iter': 2000, 'inner_loop_verbose': 0, 'alpha': 0.9, 'beta': 1, 'R': 200000, 'N_eps': 0.0001, 'N_maxit': 100, 'is_BFGS': 'adaptive', 'linear_theta_update': 'cholesky_inv', 'linear_mat': None, 'q': 3, 'N': 8}.\n",
      "  2%|██▍                                                                                                  | 49/2000 [00:01<00:59, 32.89it/s, error=0.00118, GamL0=2, CV=0.0005]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<optimization_ch.one_step_opt.OneStepOpt at 0x7f4f2da0bdf0>, (50, 2000))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "N = 8\n",
    "lam = 0.5\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "        \n",
    "_paras = edict(paras.copy())\n",
    "_paras.Rv = _paras.Rfct * _paras.Rmin\n",
    "_paras.R = _paras.Rfct * _paras.Rmin\n",
    "_paras.seed = seed\n",
    "_paras.lam = lam\n",
    "_paras.N = N\n",
    "_paras.basis_mat = _paras.basis_mats[_paras.can_Ns.index(N)]\n",
    "_paras.Gam_GT_est = paras.Gam_GT_ests[_paras.can_Ns.index(N)]\n",
    "cur_data = _gen_simu_data_all1(_paras.seed, _paras)\n",
    "    \n",
    "    \n",
    "    \n",
    "# do sure independent screening for dim reduction\n",
    "if _paras.SIS_ratio < 1:\n",
    "    keep_idxs, _ = SIS_GLIM(Y=cur_data.Y, X=cur_data.X, Z=cur_data.Z, \n",
    "                             basis_mat=_paras.SIS_basis_mat, \n",
    "                             keep_ratio=_paras.SIS_ratio, \n",
    "                             model_type=\"logi\", \n",
    "                             SIS_pen=_paras.SIS_pen, \n",
    "                             sel_idx=_paras.sel_idx)\n",
    "else:\n",
    "    keep_idxs = _paras.sel_idx\n",
    "M_idxs = np.delete(np.arange(_paras.d), _paras.sel_idx)\n",
    "_paras.keep_idxs = np.sort(np.concatenate([M_idxs, keep_idxs]))\n",
    "    \n",
    "_paras.sel_idx_SIS = np.where(np.array([keep_idx in _paras.sel_idx for keep_idx in _paras.keep_idxs]))[0]\n",
    "_paras.d_SIS = len(_paras.keep_idxs)\n",
    "\n",
    "cur_data_SIS = edict(cur_data.copy())\n",
    "cur_data_SIS.X = cur_data.X[:, _paras.keep_idxs, :]\n",
    "\n",
    "\n",
    "if _paras.init_noise_sd < 0:\n",
    "    alp_init = torch.zeros(_paras.q)\n",
    "    Gam_init = torch.zeros(_paras.N, _paras.d_SIS)\n",
    "    theta_init = torch.cat([alp_init, col_vec_fn(Gam_init)/np.sqrt(_paras.N)])\n",
    "    rhok_init = torch.zeros(_paras.d_SIS*_paras.N)\n",
    "else:\n",
    "    alp_init = torch.Tensor(_paras.alp_GT) + torch.randn(_paras.q)*_paras.init_noise_sd\n",
    "    Gam_init = torch.Tensor(_paras.Gam_GT_est[:, _paras.keep_idxs]) + torch.randn(_paras.N, _paras.d_SIS)*_paras.init_noise_sd\n",
    "    theta_init = torch.cat([alp_init, col_vec_fn(Gam_init)/np.sqrt(_paras.N)])\n",
    "    rhok_init = torch.randn(_paras.d_SIS*_paras.N)\n",
    "    \n",
    "\n",
    "model = LogisticModel(Y=cur_data_SIS.Y, \n",
    "                      X=cur_data_SIS.X, \n",
    "                      Z=cur_data_SIS.Z, \n",
    "                      basis_mat=_paras.basis_mat)\n",
    "# 3e0\n",
    "pen = SCAD(lams=_paras.lam, a=_paras.a,  sel_idx=_paras.sel_idx_SIS)\n",
    "    \n",
    "\n",
    "main_res = optimization(model=model, \n",
    "                        penalty=pen, \n",
    "                        inits=[ Gam_init, theta_init, rhok_init],\n",
    "                        verbose=2,\n",
    "                        alpha=_paras.alpha,\n",
    "                        beta=_paras.beta, \n",
    "                        R = _paras.R,\n",
    "                        stop_cv=_paras.stop_cv,\n",
    "                        max_iter=_paras.max_iter,\n",
    "                        is_BFGS= _paras.is_BFGS, \n",
    "                        N_eps=_paras.N_eps, \n",
    "                        N_maxit=_paras.N_maxit,\n",
    "                        inner_loop_verbose=0, \n",
    "                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17a0b052-c481-46bc-867a-ced147f8ea27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T01:44:37.720528Z",
     "iopub.status.busy": "2023-12-29T01:44:37.720373Z",
     "iopub.status.idle": "2023-12-29T01:44:39.386904Z",
     "shell.execute_reply": "2023-12-29T01:44:39.386469Z",
     "shell.execute_reply.started": "2023-12-29T01:44:37.720514Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 17:44:37,739 - optimization_ch.opt - INFO - opt parmas is {'stop_cv': 0.0005, 'max_iter': 2000, 'inner_loop_verbose': 0, 'alpha': 0.9, 'beta': 1.0, 'R': 200000, 'N_eps': 0.0001, 'N_maxit': 100, 'is_BFGS': 'adaptive', 'linear_theta_update': 'cholesky_inv', 'linear_mat': None, 'is_full': False}.\n",
      "2023-12-28 17:44:37,739 - optimization_ch.opt - INFO - SIS parmas is {'SIS_ratio': 0.2, 'SIS_pen': 0.02, 'SIS_basis_N': 8, 'SIS_basis_ord': 4}.\n",
      "2023-12-28 17:44:37,740 - optimization_ch.opt - INFO - model parmas is {'norminal_sigma2': 1}.\n",
      "2023-12-28 17:44:37,940 - optimization_ch.opt - INFO - The paras is {'stop_cv': 0.0005, 'max_iter': 2000, 'inner_loop_verbose': 0, 'alpha': 0.9, 'beta': 1.0, 'R': 200000, 'N_eps': 0.0001, 'N_maxit': 100, 'is_BFGS': 'adaptive', 'linear_theta_update': 'cholesky_inv', 'linear_mat': None, 'q': 3, 'N': 8}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  7 26 31 35 36 37 42 47 50 58 61 67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▍                                                                                                  | 49/2000 [00:01<00:57, 34.05it/s, error=0.00118, GamL0=2, CV=0.0005]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<optimization_ch.one_step_opt.OneStepOpt at 0x7f4f2d461fd0>, (50, 2000))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_res2 = HDF_opt(X=cur_data.X, Y=cur_data.Y, Z=cur_data.Z, is_std=False, model_type=\"logi\",\n",
    "        SIS_ratio=_paras.SIS_ratio, lam=lam, N=N, sel_idx=_paras.sel_idx, opt_params={\"beta\":1.0, \"R\":_paras.R})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0d8ca95-c89f-441f-8af6-79fc0135ecca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T01:44:40.692131Z",
     "iopub.status.busy": "2023-12-29T01:44:40.691494Z",
     "iopub.status.idle": "2023-12-29T01:44:40.734945Z",
     "shell.execute_reply": "2023-12-29T01:44:40.734222Z",
     "shell.execute_reply.started": "2023-12-29T01:44:40.692084Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_res, main_res2\n",
    "main_res[0].Gamk- main_res2[0].Gamk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff814f9-cf76-43f6-957a-26d25c6f4325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
